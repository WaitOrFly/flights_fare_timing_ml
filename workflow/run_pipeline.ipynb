{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "053c0118-b973-4900-a357-4d508098a4d9",
   "metadata": {},
   "source": [
    "## Run Workflow using Step Decorators\n",
    "\n",
    "The code and notebook in this directory shows how we can create a complete pipeline with step decorators (see `pipeline.py`).\n",
    "Each step of the pipeline is shown under the same run in MLflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01d7e95-186a-4aee-ad93-be6223b79ae9",
   "metadata": {},
   "source": [
    "Let's first install the dependencies required to run this code locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f7e4b6c-f8c9-4a7a-b24f-2b3751203913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sagemaker==2.219.0 (from -r requirements.txt (line 1))\n",
      "  Downloading sagemaker-2.219.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting scikit-learn==1.3.2 (from -r requirements.txt (line 2))\n",
      "  Downloading scikit_learn-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting xgboost==1.7.6 (from -r requirements.txt (line 3))\n",
      "  Downloading xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
      "Collecting joblib==1.5.1 (from -r requirements.txt (line 4))\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: s3fs in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (2024.12.0)\n",
      "Collecting mlflow==2.17.0 (from -r requirements.txt (line 6))\n",
      "  Downloading mlflow-2.17.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: sagemaker-mlflow in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (1.26.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (2.3.3)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (1.37.3)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.219.0->-r requirements.txt (line 1)) (23.2.0)\n",
      "Collecting cloudpickle==2.2.1 (from sagemaker==2.219.0->-r requirements.txt (line 1))\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.219.0->-r requirements.txt (line 1)) (0.2.0)\n",
      "Collecting protobuf<5.0,>=3.12 (from sagemaker==2.219.0->-r requirements.txt (line 1))\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.219.0->-r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.219.0->-r requirements.txt (line 1)) (6.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.219.0->-r requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.219.0->-r requirements.txt (line 1)) (0.3.4)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.219.0->-r requirements.txt (line 1)) (0.7.7)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.219.0->-r requirements.txt (line 1)) (6.0.3)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.219.0->-r requirements.txt (line 1)) (4.23.0)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.219.0->-r requirements.txt (line 1)) (4.5.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.219.0->-r requirements.txt (line 1)) (3.2.2)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.219.0->-r requirements.txt (line 1)) (1.26.20)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.219.0->-r requirements.txt (line 1)) (2.32.5)\n",
      "Requirement already satisfied: docker in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.219.0->-r requirements.txt (line 1)) (7.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.219.0->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.219.0->-r requirements.txt (line 1)) (5.9.8)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn==1.3.2->-r requirements.txt (line 2)) (1.16.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn==1.3.2->-r requirements.txt (line 2)) (3.6.0)\n",
      "Collecting mlflow-skinny==2.17.0 (from mlflow==2.17.0->-r requirements.txt (line 6))\n",
      "  Downloading mlflow_skinny-2.17.0-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: Flask<4 in /opt/conda/lib/python3.12/site-packages (from mlflow==2.17.0->-r requirements.txt (line 6)) (3.1.2)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /opt/conda/lib/python3.12/site-packages (from mlflow==2.17.0->-r requirements.txt (line 6)) (1.17.2)\n",
      "Requirement already satisfied: graphene<4 in /opt/conda/lib/python3.12/site-packages (from mlflow==2.17.0->-r requirements.txt (line 6)) (3.4.3)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /opt/conda/lib/python3.12/site-packages (from mlflow==2.17.0->-r requirements.txt (line 6)) (3.10)\n",
      "Requirement already satisfied: matplotlib<4 in /opt/conda/lib/python3.12/site-packages (from mlflow==2.17.0->-r requirements.txt (line 6)) (3.10.8)\n",
      "Collecting pyarrow<18,>=4.0.0 (from mlflow==2.17.0->-r requirements.txt (line 6))\n",
      "  Downloading pyarrow-17.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from mlflow==2.17.0->-r requirements.txt (line 6)) (2.0.45)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /opt/conda/lib/python3.12/site-packages (from mlflow==2.17.0->-r requirements.txt (line 6)) (3.1.6)\n",
      "Requirement already satisfied: gunicorn<24 in /opt/conda/lib/python3.12/site-packages (from mlflow==2.17.0->-r requirements.txt (line 6)) (23.0.0)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.17.0->mlflow==2.17.0->-r requirements.txt (line 6)) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.17.0->mlflow==2.17.0->-r requirements.txt (line 6)) (8.3.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.17.0->mlflow==2.17.0->-r requirements.txt (line 6)) (0.74.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.17.0->mlflow==2.17.0->-r requirements.txt (line 6)) (3.1.45)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.17.0->mlflow==2.17.0->-r requirements.txt (line 6)) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.17.0->mlflow==2.17.0->-r requirements.txt (line 6)) (1.39.1)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.17.0->mlflow==2.17.0->-r requirements.txt (line 6)) (0.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 9)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 9)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 9)) (2025.3)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.3 in /opt/conda/lib/python3.12/site-packages (from boto3->-r requirements.txt (line 10)) (1.37.3)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from boto3->-r requirements.txt (line 10)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /opt/conda/lib/python3.12/site-packages (from boto3->-r requirements.txt (line 10)) (0.11.3)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.12/site-packages (from alembic!=1.10.0,<2->mlflow==2.17.0->-r requirements.txt (line 6)) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /opt/conda/lib/python3.12/site-packages (from alembic!=1.10.0,<2->mlflow==2.17.0->-r requirements.txt (line 6)) (4.15.0)\n",
      "Requirement already satisfied: google-auth~=2.0 in /opt/conda/lib/python3.12/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow==2.17.0->-r requirements.txt (line 6)) (2.43.0)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /opt/conda/lib/python3.12/site-packages (from Flask<4->mlflow==2.17.0->-r requirements.txt (line 6)) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from Flask<4->mlflow==2.17.0->-r requirements.txt (line 6)) (2.2.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from Flask<4->mlflow==2.17.0->-r requirements.txt (line 6)) (3.0.3)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from Flask<4->mlflow==2.17.0->-r requirements.txt (line 6)) (3.1.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow==2.17.0->-r requirements.txt (line 6)) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow==2.17.0->-r requirements.txt (line 6)) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow==2.17.0->-r requirements.txt (line 6)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow==2.17.0->-r requirements.txt (line 6)) (4.9.1)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /opt/conda/lib/python3.12/site-packages (from graphene<4->mlflow==2.17.0->-r requirements.txt (line 6)) (3.2.7)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /opt/conda/lib/python3.12/site-packages (from graphene<4->mlflow==2.17.0->-r requirements.txt (line 6)) (3.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.12/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker==2.219.0->-r requirements.txt (line 1)) (3.23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib<4->mlflow==2.17.0->-r requirements.txt (line 6)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib<4->mlflow==2.17.0->-r requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib<4->mlflow==2.17.0->-r requirements.txt (line 6)) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib<4->mlflow==2.17.0->-r requirements.txt (line 6)) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib<4->mlflow==2.17.0->-r requirements.txt (line 6)) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /opt/conda/lib/python3.12/site-packages (from matplotlib<4->mlflow==2.17.0->-r requirements.txt (line 6)) (3.2.5)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /opt/conda/lib/python3.12/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow==2.17.0->-r requirements.txt (line 6)) (0.60b1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 9)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->sagemaker==2.219.0->-r requirements.txt (line 1)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->sagemaker==2.219.0->-r requirements.txt (line 1)) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->sagemaker==2.219.0->-r requirements.txt (line 1)) (2025.11.12)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow==2.17.0->-r requirements.txt (line 6)) (0.6.1)\n",
      "Requirement already satisfied: greenlet>=1 in /opt/conda/lib/python3.12/site-packages (from sqlalchemy<3,>=1.4.0->mlflow==2.17.0->-r requirements.txt (line 6)) (3.3.0)\n",
      "Requirement already satisfied: aiobotocore<3.0.0,>=2.5.4 in /opt/conda/lib/python3.12/site-packages (from s3fs->-r requirements.txt (line 5)) (2.22.0)\n",
      "Requirement already satisfied: fsspec==2024.12.0.* in /opt/conda/lib/python3.12/site-packages (from s3fs->-r requirements.txt (line 5)) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.12/site-packages (from s3fs->-r requirements.txt (line 5)) (3.13.2)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /opt/conda/lib/python3.12/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs->-r requirements.txt (line 5)) (0.12.0)\n",
      "Requirement already satisfied: multidict<7.0.0,>=6.0.0 in /opt/conda/lib/python3.12/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs->-r requirements.txt (line 5)) (6.7.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /opt/conda/lib/python3.12/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs->-r requirements.txt (line 5)) (1.17.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs->-r requirements.txt (line 5)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs->-r requirements.txt (line 5)) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs->-r requirements.txt (line 5)) (1.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs->-r requirements.txt (line 5)) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs->-r requirements.txt (line 5)) (1.22.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.12/site-packages (from jsonschema->sagemaker==2.219.0->-r requirements.txt (line 1)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.12/site-packages (from jsonschema->sagemaker==2.219.0->-r requirements.txt (line 1)) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from jsonschema->sagemaker==2.219.0->-r requirements.txt (line 1)) (0.30.0)\n",
      "Requirement already satisfied: ppft>=1.7.7 in /opt/conda/lib/python3.12/site-packages (from pathos->sagemaker==2.219.0->-r requirements.txt (line 1)) (1.7.7)\n",
      "Requirement already satisfied: dill>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from pathos->sagemaker==2.219.0->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: pox>=0.3.6 in /opt/conda/lib/python3.12/site-packages (from pathos->sagemaker==2.219.0->-r requirements.txt (line 1)) (0.3.6)\n",
      "Requirement already satisfied: multiprocess>=0.70.18 in /opt/conda/lib/python3.12/site-packages (from pathos->sagemaker==2.219.0->-r requirements.txt (line 1)) (0.70.18)\n",
      "Downloading sagemaker-2.219.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m180.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading mlflow-2.17.0-py3-none-any.whl (26.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Downloading mlflow_skinny-2.17.0-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m243.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Downloading pyarrow-17.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m233.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow, protobuf, joblib, cloudpickle, xgboost, scikit-learn, sagemaker, mlflow-skinny, mlflow\n",
      "\u001b[2K  Attempting uninstall: pyarrow\n",
      "\u001b[2K    Found existing installation: pyarrow 19.0.1\n",
      "\u001b[2K    Uninstalling pyarrow-19.0.1:\n",
      "\u001b[2K      Successfully uninstalled pyarrow-19.0.1━━━\u001b[0m \u001b[32m0/9\u001b[0m [pyarrow]\n",
      "\u001b[2K  Attempting uninstall: protobuf━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/9\u001b[0m [pyarrow]\n",
      "\u001b[2K    Found existing installation: protobuf 5.28.3━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/9\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling protobuf-5.28.3:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/9\u001b[0m [protobuf]\n",
      "\u001b[2K      Successfully uninstalled protobuf-5.28.3━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/9\u001b[0m [protobuf]\n",
      "\u001b[2K  Attempting uninstall: joblib━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/9\u001b[0m [protobuf]\n",
      "\u001b[2K    Found existing installation: joblib 1.5.2━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/9\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling joblib-1.5.2:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/9\u001b[0m [protobuf]\n",
      "\u001b[2K      Successfully uninstalled joblib-1.5.2━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/9\u001b[0m [protobuf]\n",
      "\u001b[2K  Attempting uninstall: cloudpickle━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/9\u001b[0m [joblib]\n",
      "\u001b[2K    Found existing installation: cloudpickle 3.1.2━━━━━━━━━━━━\u001b[0m \u001b[32m2/9\u001b[0m [joblib]\n",
      "\u001b[2K    Uninstalling cloudpickle-3.1.2:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/9\u001b[0m [joblib]\n",
      "\u001b[2K      Successfully uninstalled cloudpickle-3.1.2━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/9\u001b[0m [joblib]\n",
      "\u001b[2K  Attempting uninstall: xgboost━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/9\u001b[0m [joblib]\n",
      "\u001b[2K    Found existing installation: xgboost 2.1.4━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/9\u001b[0m [joblib]\n",
      "\u001b[2K    Uninstalling xgboost-2.1.4:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/9\u001b[0m [joblib]\n",
      "\u001b[2K      Successfully uninstalled xgboost-2.1.4━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/9\u001b[0m [joblib]\n",
      "\u001b[2K  Attempting uninstall: scikit-learn[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/9\u001b[0m [xgboost]\n",
      "\u001b[2K    Found existing installation: scikit-learn 1.7.2━━━━━━━━━━━\u001b[0m \u001b[32m4/9\u001b[0m [xgboost]\n",
      "\u001b[2K    Uninstalling scikit-learn-1.7.2:90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/9\u001b[0m [scikit-learn]\n",
      "\u001b[2K      Successfully uninstalled scikit-learn-1.7.2━━━━━━━━━━━━━\u001b[0m \u001b[32m5/9\u001b[0m [scikit-learn]\n",
      "\u001b[2K  Attempting uninstall: sagemakerm\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/9\u001b[0m [scikit-learn]\n",
      "\u001b[2K    Found existing installation: sagemaker 2.245.0━━━━━━━━━━━━\u001b[0m \u001b[32m5/9\u001b[0m [scikit-learn]\n",
      "\u001b[2K    Uninstalling sagemaker-2.245.0:[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m6/9\u001b[0m [sagemaker]\n",
      "\u001b[2K      Successfully uninstalled sagemaker-2.245.0m━━━━━━━━━━━━━\u001b[0m \u001b[32m6/9\u001b[0m [sagemaker]\n",
      "\u001b[2K  Attempting uninstall: mlflow-skinnym\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m6/9\u001b[0m [sagemaker]\n",
      "\u001b[2K    Found existing installation: mlflow-skinny 2.22.0━━━━━━━━━\u001b[0m \u001b[32m6/9\u001b[0m [sagemaker]\n",
      "\u001b[2K    Uninstalling mlflow-skinny-2.22.0:━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m7/9\u001b[0m [mlflow-skinny]\n",
      "\u001b[2K      Successfully uninstalled mlflow-skinny-2.22.090m━━━━━━━━\u001b[0m \u001b[32m7/9\u001b[0m [mlflow-skinny]\n",
      "\u001b[2K  Attempting uninstall: mlflow━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m7/9\u001b[0m [mlflow-skinny]\n",
      "\u001b[2K    Found existing installation: mlflow 2.22.0[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m7/9\u001b[0m [mlflow-skinny]\n",
      "\u001b[2K    Uninstalling mlflow-2.22.0:━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m7/9\u001b[0m [mlflow-skinny]\n",
      "\u001b[2K      Successfully uninstalled mlflow-2.22.0[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m8/9\u001b[0m [mlflow]ny]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9/9\u001b[0m [mlflow]2m8/9\u001b[0m [mlflow]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.4.0 requires nvidia-ml-py3<8.0,>=7.352.0, which is not installed.\n",
      "jupyter-ai 2.31.7 requires faiss-cpu!=1.8.0.post0,<2.0.0,>=1.8.0, which is not installed.\n",
      "sagemaker-studio 1.1.4 requires pydynamodb>=0.7.4, which is not installed.\n",
      "autogluon-core 1.4.0 requires scikit-learn<1.8.0,>=1.4.0, but you have scikit-learn 1.3.2 which is incompatible.\n",
      "autogluon-features 1.4.0 requires scikit-learn<1.8.0,>=1.4.0, but you have scikit-learn 1.3.2 which is incompatible.\n",
      "autogluon-multimodal 1.4.0 requires scikit-learn<1.8.0,>=1.4.0, but you have scikit-learn 1.3.2 which is incompatible.\n",
      "autogluon-multimodal 1.4.0 requires transformers[sentencepiece]<4.50,>=4.38.0, but you have transformers 4.57.3 which is incompatible.\n",
      "autogluon-tabular 1.4.0 requires scikit-learn<1.8.0,>=1.4.0, but you have scikit-learn 1.3.2 which is incompatible.\n",
      "autogluon-timeseries 1.4.0 requires transformers[sentencepiece]<4.50,>=4.38.0, but you have transformers 4.57.3 which is incompatible.\n",
      "dask 2025.12.0 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\n",
      "distributed 2025.12.0 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\n",
      "grpcio-status 1.67.1 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
      "sagemaker-studio 1.1.4 requires pyarrow>=19.0.0, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed cloudpickle-2.2.1 joblib-1.5.1 mlflow-2.17.0 mlflow-skinny-2.17.0 protobuf-4.25.8 pyarrow-17.0.0 sagemaker-2.219.0 scikit-learn-1.3.2 xgboost-1.7.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6539d0-c10f-4b75-949e-4a125a7d0980",
   "metadata": {},
   "source": [
    "Lets restore the variables from the `00-start-here` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a3fce6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting joblib==1.5.3\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Installing collected packages: joblib\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.5.1\n",
      "    Uninstalling joblib-1.5.1:\n",
      "      Successfully uninstalled joblib-1.5.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.4.0 requires nvidia-ml-py3<8.0,>=7.352.0, which is not installed.\n",
      "autogluon-core 1.4.0 requires scikit-learn<1.8.0,>=1.4.0, but you have scikit-learn 1.3.2 which is incompatible.\n",
      "autogluon-features 1.4.0 requires scikit-learn<1.8.0,>=1.4.0, but you have scikit-learn 1.3.2 which is incompatible.\n",
      "autogluon-multimodal 1.4.0 requires scikit-learn<1.8.0,>=1.4.0, but you have scikit-learn 1.3.2 which is incompatible.\n",
      "autogluon-multimodal 1.4.0 requires transformers[sentencepiece]<4.50,>=4.38.0, but you have transformers 4.57.3 which is incompatible.\n",
      "autogluon-tabular 1.4.0 requires scikit-learn<1.8.0,>=1.4.0, but you have scikit-learn 1.3.2 which is incompatible.\n",
      "autogluon-timeseries 1.4.0 requires transformers[sentencepiece]<4.50,>=4.38.0, but you have transformers 4.57.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed joblib-1.5.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting xgboost==3.1.3\n",
      "  Downloading xgboost-3.1.3-py3-none-manylinux_2_28_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from xgboost==3.1.3) (1.26.4)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost==3.1.3)\n",
      "  Downloading nvidia_nccl_cu12-2.29.2-py3-none-manylinux_2_18_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.12/site-packages (from xgboost==3.1.3) (1.16.3)\n",
      "Downloading xgboost-3.1.3-py3-none-manylinux_2_28_x86_64.whl (115.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 MB\u001b[0m \u001b[31m137.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.29.2-py3-none-manylinux_2_18_x86_64.whl (289.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.8/289.8 MB\u001b[0m \u001b[31m135.7 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n",
      "\u001b[2K  Attempting uninstall: xgboost━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Found existing installation: xgboost 1.7.60m \u001b[32m0/2\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling xgboost-1.7.6:━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled xgboost-1.7.6\u001b[0m \u001b[32m0/2\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [xgboost]m1/2\u001b[0m [xgboost]\n",
      "\u001b[1A\u001b[2KSuccessfully installed nvidia-nccl-cu12-2.29.2 xgboost-3.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install joblib==1.5.3\n",
    "%pip install xgboost==3.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6bcc443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.9 | packaged by conda-forge | (main, Feb 14 2025, 08:00:06) [GCC 13.3.0]\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "sagemaker: 2.219.0\n",
      "boto3: 1.37.3\n",
      "mlflow: 2.17.0\n",
      "xgboost: 3.1.3\n",
      "numpy: 1.26.4\n",
      "pandas: 2.3.3\n",
      "sklearn: 1.3.2\n",
      "scipy: 1.16.3\n",
      "joblib: 1.5.3\n",
      "sagemaker-mlflow: 0.2.0\n",
      "s3fs: 2024.12.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import importlib\n",
    "\n",
    "packages = [\n",
    "    \"sagemaker\",\n",
    "    \"boto3\",\n",
    "    \"mlflow\",\n",
    "    \"xgboost\",\n",
    "    \"numpy\",\n",
    "    \"pandas\",\n",
    "    \"sklearn\",\n",
    "    \"scipy\",\n",
    "    \"joblib\",\n",
    "    \"sagemaker-mlflow\",\n",
    "    \"s3fs\",\n",
    "]\n",
    "\n",
    "print(f\"Python: {sys.version}\")\n",
    "\n",
    "for pkg in packages:\n",
    "    try:\n",
    "        module_name = pkg.replace(\"-\", \"_\")\n",
    "        mod = importlib.import_module(module_name)\n",
    "        version = getattr(mod, \"__version__\", \"unknown\")\n",
    "        print(f\"{pkg}: {version}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{pkg}: not importable ({e})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a780a112-657c-4442-9681-2de9cc601a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "bucket_prefix              -> 'sagemaker-us-east-1-632458605453/flights'\n",
      "domain_id                  -> 'd-cyjixw7xaezf'\n",
      "initialized                -> True\n",
      "mlflow_arn                 -> 'arn:aws:sagemaker:us-east-1:632458605453:mlflow-t\n",
      "mlflow_name                -> 'mlflow-d-cyjixw7xaezf'\n",
      "project_prefix             -> 'flights'\n",
      "region                     -> 'us-east-1'\n"
     ]
    }
   ],
   "source": [
    "%store -r \n",
    "\n",
    "%store\n",
    "\n",
    "try:\n",
    "    initialized\n",
    "except NameError:    \n",
    "    print(\"[ERROR] YOU HAVE TO RUN 00-start-here notebook   \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecc88b1-fffe-49f4-8db6-6ba813ad555d",
   "metadata": {},
   "source": [
    "Lets create a config which will be used by default for each step. \n",
    "\n",
    "Note that we define the `S3RootUri` to customize the S3 location that will be used for the artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b20f6233-a82a-48a3-b9bf-76312b5b9f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SchemaVersion: '1.0'\n",
      "SageMaker:\n",
      "  PythonSDK:\n",
      "    Modules:\n",
      "      RemoteFunction:\n",
      "        S3RootUri: s3://sagemaker-us-east-1-632458605453/flights\n",
      "        InstanceType: ml.m5.xlarge\n",
      "        Dependencies: /home/sagemaker-user/flights_fare_timing_ml/workflow/requirements.txt\n",
      "        IncludeLocalWorkDir: true\n",
      "        PreExecutionCommands:\n",
      "          - \"conda install -y -c conda-forge libstdcxx-ng libgcc-ng\"\n",
      "          - \"conda remove -y xgboost\"\n",
      "          - \"pip install --force-reinstall xgboost==1.7.6\"\n",
      "          - \"sudo bash -c 'echo /opt/conda/lib > /etc/ld.so.conf.d/conda.conf'\"\n",
      "          - \"sudo ldconfig\"\n",
      "          - \"sudo chmod -R 777 /opt/ml/model\"\n",
      "        CustomFileFilter:\n",
      "          IgnoreNamePatterns:\n",
      "            - \"data/*\"\n",
      "            - \"models/*\"\n",
      "            - \"*.ipynb\"\n",
      "            - \"__pycache__\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_yaml = f\"\"\"\n",
    "SchemaVersion: '1.0'\n",
    "SageMaker:\n",
    "  PythonSDK:\n",
    "    Modules:\n",
    "      RemoteFunction:\n",
    "        S3RootUri: s3://{bucket_prefix}\n",
    "        InstanceType: ml.m5.xlarge\n",
    "        Dependencies: /home/sagemaker-user/flights_fare_timing_ml/workflow/requirements.txt\n",
    "        IncludeLocalWorkDir: true\n",
    "        PreExecutionCommands:\n",
    "          - \"conda install -y -c conda-forge libstdcxx-ng libgcc-ng\"\n",
    "          - \"conda remove -y xgboost\"\n",
    "          - \"pip install --force-reinstall xgboost==1.7.6\"\n",
    "          - \"sudo bash -c 'echo /opt/conda/lib > /etc/ld.so.conf.d/conda.conf'\"\n",
    "          - \"sudo ldconfig\"\n",
    "          - \"sudo chmod -R 777 /opt/ml/model\"\n",
    "        CustomFileFilter:\n",
    "          IgnoreNamePatterns:\n",
    "            - \"data/*\"\n",
    "            - \"models/*\"\n",
    "            - \"*.ipynb\"\n",
    "            - \"__pycache__\"\n",
    "\n",
    "\"\"\"\n",
    "print(config_yaml, file=open('config.yaml', 'w'))\n",
    "print(config_yaml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21ab9de8-a6fc-423b-b924-696498a42da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Fetched defaults config from location: /home/sagemaker-user/flights_fare_timing_ml/workflow\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "/opt/conda/lib/python3.12/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"MLFLOW_TRACKING_ARN\"] = mlflow_arn\n",
    "os.environ[\"PROJECT_PREFIX\"] = project_prefix\n",
    "os.environ[\"BUCKET_PREFIX\"] = bucket_prefix\n",
    "os.environ[\"INPUT_DATA_S3_URI\"] = f\"s3://{bucket_prefix}/data/flight_fares.csv\"\n",
    "os.environ[\"OUTPUT_DATA_S3_URI\"] = f\"s3://{bucket_prefix}/processed\"\n",
    "!python pipeline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d4b500-a2c3-4745-95c0-f299ab856ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배포 후 추론 테스트 코드\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "endpoint_name = \"flights-endpoint-1768191960-25f5\"\n",
    "runtime = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "payload = \"0,afternoon,1,0,1,3091900015,1,long\"\n",
    "\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/octet-stream\",\n",
    "    Body=payload.encode(\"utf-8\"),\n",
    ")\n",
    "\n",
    "raw = response[\"Body\"].read()\n",
    "preds = np.load(io.BytesIO(raw))\n",
    "\n",
    "print(preds)\n",
    "print(np.expm1(0.68778))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfbb6f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_log: 9.993353\n",
      "pred_expm1: 21879.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_362859/2548478968.py:33: UserWarning: [04:37:28] WARNING: /workspace/src/c_api/c_api.cc:1511: Unknown file format: `bin`. Using UBJSON (`ubj`) as a guess.\n",
      "  booster.load_model(BOOSTER_PATH)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "FEATURIZER_PATH = \"../sklearn_model.joblib\"\n",
    "BOOSTER_PATH = \"../xgboost_model.bin\"\n",
    "\n",
    "feature_order = [\n",
    "    \"purchase_day_of_week\",\n",
    "    \"purchase_time_bucket\",\n",
    "    \"days_until_departure\",\n",
    "    \"is_weekend_departure\",\n",
    "    \"is_holiday_season\",\n",
    "    \"route_hash\",\n",
    "    \"stops_count\",\n",
    "    \"flight_duration_bucket\",\n",
    "]\n",
    "\n",
    "row = {\n",
    "    \"purchase_day_of_week\": 5,\n",
    "    \"purchase_time_bucket\": \"dawn\",\n",
    "    \"days_until_departure\": 26,\n",
    "    \"is_weekend_departure\": 0,\n",
    "    \"is_holiday_season\": 1,\n",
    "    \"route_hash\": 3091900015,\n",
    "    \"stops_count\": 1,\n",
    "    \"flight_duration_bucket\": \"long\",\n",
    "}\n",
    "\n",
    "featurizer = joblib.load(FEATURIZER_PATH)\n",
    "booster = xgb.Booster()\n",
    "booster.load_model(BOOSTER_PATH)\n",
    "\n",
    "df = pd.DataFrame([row], columns=feature_order)\n",
    "transformed = featurizer.transform(df)\n",
    "\n",
    "pred_log = booster.predict(xgb.DMatrix(transformed))[0]\n",
    "print(\"pred_log:\", pred_log)\n",
    "print(\"pred_expm1:\", np.expm1(pred_log))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca797ca5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['days_until_departure'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m booster\u001b[38;5;241m.\u001b[39mload_model(BOOSTER_PATH)\n\u001b[1;32m     55\u001b[0m df \u001b[38;5;241m=\u001b[39m payload_to_df(RAW_PAYLOAD)\n\u001b[0;32m---> 56\u001b[0m transformed \u001b[38;5;241m=\u001b[39m \u001b[43mfeaturizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m pred_log_local \u001b[38;5;241m=\u001b[39m booster\u001b[38;5;241m.\u001b[39mpredict(xgb\u001b[38;5;241m.\u001b[39mDMatrix(transformed))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     59\u001b[0m pred_expm1_local \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpm1(pred_log_local)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:827\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;66;03m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 827\u001b[0m Xs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfitted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_strings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_dataframe_and_transform_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Xs:\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;66;03m# All transformers are None\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:681\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[0;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[1;32m    675\u001b[0m transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(\n\u001b[1;32m    677\u001b[0m         fitted\u001b[38;5;241m=\u001b[39mfitted, replace_strings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, column_as_strings\u001b[38;5;241m=\u001b[39mcolumn_as_strings\n\u001b[1;32m    678\u001b[0m     )\n\u001b[1;32m    679\u001b[0m )\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 681\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfitted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mColumnTransformer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/joblib/parallel.py:1986\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1984\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1985\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1988\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1989\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1990\u001b[0m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1991\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1992\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1993\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/joblib/parallel.py:1911\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1908\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1910\u001b[0m \u001b[38;5;66;03m# Sequentially call the tasks and yield the results.\u001b[39;00m\n\u001b[0;32m-> 1911\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1912\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_dispatched_batches\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m   1913\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_dispatched_tasks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Capture the thread-local scikit-learn configuration at the time\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Parallel.__call__ is issued since the tasks can be dispatched\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# in a different thread depending on the backend and on the value of\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# pre_dispatch and n_jobs.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_with_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m---> 63\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdelayed_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:684\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    675\u001b[0m transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(\n\u001b[1;32m    677\u001b[0m         fitted\u001b[38;5;241m=\u001b[39mfitted, replace_strings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, column_as_strings\u001b[38;5;241m=\u001b[39mcolumn_as_strings\n\u001b[1;32m    678\u001b[0m     )\n\u001b[1;32m    679\u001b[0m )\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    681\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[1;32m    682\u001b[0m         delayed(func)(\n\u001b[1;32m    683\u001b[0m             transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[0;32m--> 684\u001b[0m             X\u001b[38;5;241m=\u001b[39m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    685\u001b[0m             y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    686\u001b[0m             weight\u001b[38;5;241m=\u001b[39mweight,\n\u001b[1;32m    687\u001b[0m             message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    688\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(name, idx, \u001b[38;5;28mlen\u001b[39m(transformers)),\n\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, trans, column, weight) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(transformers, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    691\u001b[0m     )\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/sklearn/utils/__init__.py:353\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[0;34m(X, indices, axis)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    348\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecifying the columns using strings is only supported for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    349\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas DataFrames\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    350\u001b[0m     )\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pandas_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/sklearn/utils/__init__.py:199\u001b[0m, in \u001b[0;36m_pandas_indexing\u001b[0;34m(X, key, key_dtype, axis)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;66;03m# check whether we should index with loc or iloc\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc \u001b[38;5;28;01mif\u001b[39;00m key_dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mloc\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexer\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;28;01melse\u001b[39;00m indexer[key]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/indexing.py:1185\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[0;32m-> 1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1187\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/indexing.py:1378\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take(tup)\n\u001b[0;32m-> 1378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple_same_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/indexing.py:1021\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_null_slice(key):\n\u001b[1;32m   1019\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m-> 1021\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mretval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;66;03m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m retval\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/indexing.py:1421\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1419\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1421\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1423\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/indexing.py:1361\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1361\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1363\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1364\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/indexing.py:1559\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1556\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1557\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1559\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/indexes/base.py:6212\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6210\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6212\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6214\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6216\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/indexes/base.py:6264\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6263\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6264\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['days_until_departure'] not in index\""
     ]
    }
   ],
   "source": [
    "import io\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "FEATURIZER_PATH = \"/home/sagemaker-user/flights_fare_timing_ml/serve_extracted/sklearn_model.joblib\"\n",
    "BOOSTER_PATH = \"/home/sagemaker-user/flights_fare_timing_ml/serve_extracted2/xgboost_model.bin\"\n",
    "\n",
    "# Lambda에 보낸 raw CSV (그대로)\n",
    "RAW_PAYLOAD = \"0,afternoon,1,0,1,3091900015,1,long\"\n",
    "\n",
    "# Lambda에서 받은 log-scale 예측값(예: 0.7937496)\n",
    "LAMBDA_PRED_LOG = 0.7937496\n",
    "\n",
    "FEATURE_ORDER = [\n",
    "    \"purchase_day_of_week\",\n",
    "    \"purchase_time_bucket\",\n",
    "    \"days_until_departure_bucket\",\n",
    "    \"is_weekend_departure\",\n",
    "    \"is_holiday_season\",\n",
    "    \"route_hash\",\n",
    "    \"stops_count\",\n",
    "    \"flight_duration_bucket\",\n",
    "]\n",
    "\n",
    "NUMERIC_FIELDS = {\n",
    "    \"purchase_day_of_week\",\n",
    "    \"days_until_departure_bucket\",\n",
    "    \"is_weekend_departure\",\n",
    "    \"is_holiday_season\",\n",
    "    \"route_hash\",\n",
    "    \"stops_count\",\n",
    "}\n",
    "\n",
    "def payload_to_df(payload: str) -> pd.DataFrame:\n",
    "    parts = [p.strip() for p in payload.split(\",\")]\n",
    "    if len(parts) != len(FEATURE_ORDER):\n",
    "        raise ValueError(f\"Expected {len(FEATURE_ORDER)} fields, got {len(parts)}: {parts}\")\n",
    "    row = {}\n",
    "    for name, value in zip(FEATURE_ORDER, parts):\n",
    "        if name in NUMERIC_FIELDS:\n",
    "            try:\n",
    "                row[name] = int(value)\n",
    "            except ValueError:\n",
    "                row[name] = float(value)\n",
    "        else:\n",
    "            row[name] = value\n",
    "    return pd.DataFrame([row], columns=FEATURE_ORDER)\n",
    "\n",
    "featurizer = joblib.load(FEATURIZER_PATH)\n",
    "booster = xgb.Booster()\n",
    "booster.load_model(BOOSTER_PATH)\n",
    "\n",
    "df = payload_to_df(RAW_PAYLOAD)\n",
    "transformed = featurizer.transform(df)\n",
    "\n",
    "pred_log_local = booster.predict(xgb.DMatrix(transformed))[0]\n",
    "pred_expm1_local = np.expm1(pred_log_local)\n",
    "\n",
    "print(\"LOCAL preds_log:\", pred_log_local)\n",
    "print(\"LOCAL preds_expm1:\", pred_expm1_local)\n",
    "print(\"LAMBDA preds_log:\", LAMBDA_PRED_LOG)\n",
    "print(\"LAMBDA preds_expm1:\", np.expm1(LAMBDA_PRED_LOG))\n",
    "print(\"log diff:\", pred_log_local - LAMBDA_PRED_LOG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba995efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed shape: (1, 10)\n",
      "roundtrip equal: True\n",
      "roundtrip shape: (1, 10)\n",
      "preds_log: [0.7937496] [0.7937496]\n",
      "preds_expm1: [1.2116737] [1.2116737]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.2.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator FunctionTransformer from version 1.2.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator ColumnTransformer from version 1.2.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "FEATURIZER_PATH = \"/home/sagemaker-user/flights_fare_timing_ml/serve_extracted/sklearn_model.joblib\"\n",
    "BOOSTER_PATH = \"/home/sagemaker-user/flights_fare_timing_ml/serve_extracted2/xgboost_model.bin\"\n",
    "\n",
    "feature_order = [\n",
    "    \"purchase_day_of_week\",\n",
    "    \"purchase_time_bucket\",\n",
    "    \"days_until_departure_bucket\",\n",
    "    \"is_weekend_departure\",\n",
    "    \"is_holiday_season\",\n",
    "    \"route_hash\",\n",
    "    \"stops_count\",\n",
    "    \"flight_duration_bucket\",\n",
    "]\n",
    "\n",
    "# 샘플 입력 (필요시 값 변경)\n",
    "row = {\n",
    "    \"purchase_day_of_week\": 0,\n",
    "    \"purchase_time_bucket\": \"afternoon\",\n",
    "    \"days_until_departure_bucket\": 1,\n",
    "    \"is_weekend_departure\": 0,\n",
    "    \"is_holiday_season\": 1,\n",
    "    \"route_hash\": 3091900015,\n",
    "    \"stops_count\": 1,\n",
    "    \"flight_duration_bucket\": \"long\",\n",
    "}\n",
    "\n",
    "featurizer = joblib.load(FEATURIZER_PATH)\n",
    "booster = xgb.Booster()\n",
    "booster.load_model(BOOSTER_PATH)\n",
    "\n",
    "df = pd.DataFrame([row], columns=feature_order)\n",
    "\n",
    "# 1) featurizer -> ndarray\n",
    "transformed = featurizer.transform(df)\n",
    "print(\"transformed shape:\", transformed.shape)\n",
    "\n",
    "# 2) NPY 직렬화/역직렬화\n",
    "buf = io.BytesIO()\n",
    "np.save(buf, transformed)\n",
    "buf.seek(0)\n",
    "\n",
    "roundtrip = np.load(buf)\n",
    "print(\"roundtrip equal:\", np.allclose(transformed, roundtrip))\n",
    "print(\"roundtrip shape:\", roundtrip.shape)\n",
    "\n",
    "# 3) XGBoost 예측 비교\n",
    "pred1 = booster.predict(xgb.DMatrix(transformed))\n",
    "pred2 = booster.predict(xgb.DMatrix(roundtrip))\n",
    "print(\"preds_log:\", pred1, pred2)\n",
    "print(\"preds_expm1:\", np.expm1(pred1), np.expm1(pred2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "607a9df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed shape: (1, 10)\n",
      "roundtrip equal: True\n",
      "roundtrip shape: (1, 10)\n",
      "pred_log direct: 0.7937496\n",
      "pred_log roundtrip: 0.7937496\n",
      "pred_expm1 direct: 1.2116737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.2.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator FunctionTransformer from version 1.2.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator ColumnTransformer from version 1.2.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "FEATURIZER_PATH = \"/home/sagemaker-user/flights_fare_timing_ml/serve_extracted/sklearn_model.joblib\"\n",
    "BOOSTER_PATH = \"/home/sagemaker-user/flights_fare_timing_ml/serve_extracted2/xgboost_model.bin\"\n",
    "\n",
    "RAW_PAYLOAD = \"0,afternoon,1,0,1,3091900015,1,long\"\n",
    "\n",
    "FEATURE_ORDER = [\n",
    "    \"purchase_day_of_week\",\n",
    "    \"purchase_time_bucket\",\n",
    "    \"days_until_departure_bucket\",\n",
    "    \"is_weekend_departure\",\n",
    "    \"is_holiday_season\",\n",
    "    \"route_hash\",\n",
    "    \"stops_count\",\n",
    "    \"flight_duration_bucket\",\n",
    "]\n",
    "\n",
    "NUMERIC_FIELDS = {\n",
    "    \"purchase_day_of_week\",\n",
    "    \"days_until_departure_bucket\",\n",
    "    \"is_weekend_departure\",\n",
    "    \"is_holiday_season\",\n",
    "    \"route_hash\",\n",
    "    \"stops_count\",\n",
    "}\n",
    "\n",
    "def payload_to_df(payload: str) -> pd.DataFrame:\n",
    "    parts = [p.strip() for p in payload.split(\",\")]\n",
    "    if len(parts) != len(FEATURE_ORDER):\n",
    "        raise ValueError(f\"Expected {len(FEATURE_ORDER)} fields, got {len(parts)}: {parts}\")\n",
    "    row = {}\n",
    "    for name, value in zip(FEATURE_ORDER, parts):\n",
    "        if name in NUMERIC_FIELDS:\n",
    "            try:\n",
    "                row[name] = int(value)\n",
    "            except ValueError:\n",
    "                row[name] = float(value)\n",
    "        else:\n",
    "            row[name] = value\n",
    "    return pd.DataFrame([row], columns=FEATURE_ORDER)\n",
    "\n",
    "featurizer = joblib.load(FEATURIZER_PATH)\n",
    "booster = xgb.Booster()\n",
    "booster.load_model(BOOSTER_PATH)\n",
    "\n",
    "df = payload_to_df(RAW_PAYLOAD)\n",
    "\n",
    "# 1) featurizer 출력\n",
    "transformed = featurizer.transform(df)\n",
    "print(\"transformed shape:\", transformed.shape)\n",
    "\n",
    "# 2) NPY 직렬화 → 역직렬화 (서빙 흐름 모사)\n",
    "buf = io.BytesIO()\n",
    "np.save(buf, transformed)\n",
    "buf.seek(0)\n",
    "roundtrip = np.load(buf)\n",
    "\n",
    "print(\"roundtrip equal:\", np.allclose(transformed, roundtrip))\n",
    "print(\"roundtrip shape:\", roundtrip.shape)\n",
    "\n",
    "# 3) XGBoost 입력 비교\n",
    "pred_direct = booster.predict(xgb.DMatrix(transformed))[0]\n",
    "pred_roundtrip = booster.predict(xgb.DMatrix(roundtrip))[0]\n",
    "\n",
    "print(\"pred_log direct:\", pred_direct)\n",
    "print(\"pred_log roundtrip:\", pred_roundtrip)\n",
    "print(\"pred_expm1 direct:\", np.expm1(pred_direct))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1656050f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4040905874\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "source = \"Dubai\"\n",
    "destination = \"Kolkata\"\n",
    "\n",
    "route_str = f\"{source}_{destination}\"\n",
    "print(int(hashlib.md5(route_str.encode()).hexdigest()[:8], 16))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
